# data configs
data: 'celeba'
data_path: 'data/CelebAMask-HQ'
tasks: ['rgb', 'edge', 'pncc', 'segment']

# training configs
lr: 0.00025
lr_schedule: 'sqroot'
warmup_iters: 1000

beta: 1
beta_schedule: 'constant'

gamma_train: 0

n_steps: 200000
global_batch_size: 10

# evaluation configs
M: 30
N: 1024
K: 1
L: 1
gamma_test: 0.5
imputer_path: ''

# model configs
model: 'stp'
dim_x: 2
dim_ys: {'rgb': 3, 'edge': 1, 'pncc': 3, 'segment': 19}
dim_hidden: 512
layernorm: False
n_attn_heads: 4
module_sizes: [2, 1, 3]
stochastic_path: True
deterministic_path: True
implicit_global_latent: False

# logging configs
log_iter: 100
val_iter: 5000
save_iter: 5000
log_dir: 'runs_celeba'