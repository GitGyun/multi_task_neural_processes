### data configs

data: 'weather'
data_path: 'data/weather/weather_266cities_12tasks_258days.pth'
tasks: ['tMin_Global', 'tMax_Global', 'humidity_Global', 'precip_Global', 'cloud_Global', 'dew_Global'] # list of task names
task_types: {'tMin_Global': 'continuous', 'tMax_Global': 'continuous', 'humidity_Global': 'continuous', 'precip_Global': 'continuous',
             'cloud_Global': 'continuous', 'wind_Global': 'continuous', 'dew_Global': 'continuous'} # whether each task is continuous or discrete

dim_x: 1 # input dimension
dim_ys: {'tMin_Global': 1, 'tMax_Global': 1, 'humidity_Global': 1, 'precip_Global': 1, 'cloud_Global': 1,
         'dew_Global': 1, 'wind_Global': 1, 'pressure_Global': 1, 'ozone_Global': 1, 'uv_Global': 1} # output dimensions or channels

split_ratio: [200, 30, 36]
num_workers: 4

colors: {'tMin_Global': 'r', 'tMax_Global': 'g', 'humidity_Global': 'b', 'precip_Global': 'c', 'cloud_Global': 'm',
         'dew_Global': 'y', 'wind_Global': 'tab:purple', 'pressure_Global': 'tab:orange', 'ozone_Global': 'tab:brown', 'uv_Global': 'tab:pink'}


### training configs

n_steps: 50000 # total training steps
global_batch_size: 16 # number of datasets (multi-task functions) in a batch

lr: 0.0001 # learning rate
lr_schedule: 'sqroot'
lr_warmup: 1000

beta_G: 1 # beta coefficient for global kld
beta_G_schedule: 'linear_warmup'
beta_G_warmup: 10000

beta_T: 1 # beta coefficient for per-task klds
beta_T_schedule: 'linear_warmup'
beta_T_warmup: 10000

gamma_train: 0.5 # missing rate
cs_range_train: [10, 30] # context size, null means default range (len(tasks), ts // 2)
ts_train: 200 # target size


### validation configs

cs_valid: 20
ts_valid: 258
ns_G: 5 # number of global sampling
ns_T: 5 # number of per-task samplings

gamma_valid: 0.5 # missing rate
imputer_path: 'experiments/runs_weather/stp/checkpoints/best_error.pth' # imputer checkpoint path (for JTP)


### model configs

dim_hidden: 64 # width of the networks, serves as a basic unit in all layers except the input & output heads (and also the latent dimensions)
module_sizes: [3, 3, 2, 5] # depth of the networks: (element-wise encoder, intra-task attention, inter-task attention, element-wise decoder)
pma: True # whether to use PMA pooling rather than average pooling

attn_config:
    act_fn: 'gelu'
    ln: True # layernorm in attentions and mlps
    dr: 0.1 # dropout in mlps
    n_heads: 4 # number of attention heads
epsilon: 0.1 # minimum standard deviation for Normal latent variables


### logging configs

log_iter: 100 # interval between tqdm and tensorboard logging of training metrics
val_iter: 1000 # interval between validation and tensorboard logging of validation metrics
save_iter: 1000 # interval between checkpointing
log_dir: 'runs_weather' # directory for saving checkpoints and logs
